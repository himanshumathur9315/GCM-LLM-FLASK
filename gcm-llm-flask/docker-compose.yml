# Use a recent version of the Docker Compose file format
version: '3.8'

# Define the services (containers) that make up your application
services:
  # Name of our service
  gcm-api:
    # Tell Compose to build the image from the Dockerfile in the current directory
    build: .
    # Name the image that will be built
    image: gcm-api:latest
    # Set a name for the running container for easy reference
    container_name: gcm-container
    # Automatically restart the container if it crashes or the server reboots
    restart: unless-stopped
    # Map port 5000 on the host machine to port 5000 in the container
    ports:
      - "5000:5000"
    # Mount the local model directory into the container.
    # This is a useful optimization: if you retrain your model, you can just
    # restart the container without rebuilding the entire Docker image.
    volumes:
      - ./gcm-lora-4171-2:/app/gcm-lora-4171-2
    # This 'deploy' section is the modern way to request GPU resources.
    # It requires the NVIDIA Container Toolkit to be installed on the host.
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1  # Request exactly one GPU
              capabilities: [gpu]